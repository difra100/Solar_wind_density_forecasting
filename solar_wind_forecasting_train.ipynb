{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A CNN-LSTM framework for the solar wind density forecasting\n",
    "## ConvLSTM training\n",
    "In this notebook we train a ConvLSTM network to predict solar wind densities (electrons + protons)\n",
    "\n",
    "\n",
    "#### Notebook Contributors\n",
    "* Andrea Giuseppe Di Francesco -- email: difrancesco.1836928@studenti.uniroma1.it\n",
    "* Massimo Coppotelli -- email: coppotelli.1705325@studenti.uniroma1.it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning==1.5.10\n",
      "  Downloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.7/527.7 kB\u001b[0m \u001b[31m956.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7.* in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (1.13.1)\n",
      "Collecting setuptools==59.5.0\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m639.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (4.4.0)\n",
      "Collecting tqdm>=4.41.0\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m986.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m899.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (6.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (1.23.5)\n",
      "Collecting future>=0.17.1\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m395.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torchmetrics>=0.4.1\n",
      "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 kB\u001b[0m \u001b[31m984.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m960.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (2.28.1)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m449.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from packaging>=17.0->pytorch-lightning==1.5.10) (3.0.9)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.15.0-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.0/177.0 kB\u001b[0m \u001b[31m974.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m409.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.51.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting protobuf<4,>=3.9.2\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m370.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m424.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.38.4)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m627.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (8.5.0.96)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (2.1.1)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m329.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m755.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.16.0)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (2022.9.24)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.11.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m465.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=4a439c7bfa02d0ad0db8da86069c6d100aef7684fb5058490e5fa878cef590e2\n",
      "  Stored in directory: /home/massimo/.cache/pip/wheels/96/66/19/2de75120f5d0bc185e9d16cf0fd223d8471ed025de08e45867\n",
      "Successfully built future\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, zipp, tqdm, tensorboard-data-server, setuptools, rsa, pyDeprecate, pyasn1-modules, protobuf, oauthlib, multidict, MarkupSafe, grpcio, future, fsspec, frozenlist, cachetools, attrs, async-timeout, absl-py, yarl, werkzeug, requests-oauthlib, importlib-metadata, google-auth, aiosignal, markdown, google-auth-oauthlib, aiohttp, tensorboard, torchmetrics, pytorch-lightning\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.1\n",
      "    Uninstalling setuptools-65.5.1:\n",
      "      Successfully uninstalled setuptools-65.5.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.12\n",
      "    Uninstalling protobuf-4.21.12:\n",
      "      Successfully uninstalled protobuf-4.21.12\n",
      "Successfully installed MarkupSafe-2.1.1 absl-py-1.3.0 aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 attrs-22.2.0 cachetools-5.2.0 frozenlist-1.3.3 fsspec-2022.11.0 future-0.18.2 google-auth-2.15.0 google-auth-oauthlib-0.4.6 grpcio-1.51.1 importlib-metadata-6.0.0 markdown-3.4.1 multidict-6.0.4 oauthlib-3.2.2 protobuf-3.20.3 pyDeprecate-0.3.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch-lightning-1.5.10 requests-oauthlib-1.3.1 rsa-4.9 setuptools-59.5.0 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torchmetrics-0.11.0 tqdm-4.64.1 werkzeug-2.2.2 yarl-1.8.2 zipp-3.11.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install matplotlib\n",
    "# !pip install torchvision\n",
    "# !pip install wandb\n",
    "# !pip3 install pytorch-lightning==1.5.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "# Personal files\n",
    "from convlstm import *\n",
    "from utils import *\n",
    "from init import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcoppotelli-1705325\u001b[0m (\u001b[33msmall_sunbirds\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "if wb:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dataset = pd.read_csv('./datasets/wind_dataset_1d_res.csv', index_col = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch lightning code \n",
    "- Need of a collate function to preprocess data: sun_images are expressed as lists in a json files, thus we need a preprocessing before feed them into the ConvLSTM.\n",
    "- Then we define a Lightning DataModule, and finally the Lightining Module for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pl_Dataset_(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self,  dataset, bs):\n",
    "      \n",
    "\n",
    "      self.train_set = dataset.loc[0:round(len(dataset)*train_split)]\n",
    "      self.val_set = dataset.loc[round(len(dataset)*train_split)+1: round(len(dataset)*train_split) + round(len(dataset)*val_split)]\n",
    "\n",
    "      self.bs = bs\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        if stage == 'fit':\n",
    "            self.train_dataset = DataSet(self.train_set)\n",
    "        elif stage == 'test':\n",
    "            self.val_dataset = DataSet(self.val_set)\n",
    "            \n",
    "\n",
    "    def train_dataloader(self, *args, **kwargs):\n",
    "        return DataLoader(self.train_dataset, batch_size = self.bs, shuffle = True, collate_fn = collate) #, transform = transform)  Transformation was already made during the processing\n",
    "\n",
    "    def val_dataloader(self, *args, **kwargs):\n",
    "        return DataLoader(self.val_dataset, batch_size = self.bs, shuffle = False, collate_fn = collate) #, transform = transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SettingData = pl_Dataset_(wind_dataset, batch_size)\n",
    "\n",
    "SettingData.setup('fit')\n",
    "SettingData.setup('test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Save_Model_(Callback):\n",
    "\n",
    "  ''' This Callback is fundamental to save the model, and also its performances over time. It considers also if we want to save the model, given a path, or if we do not want to do so. '''\n",
    "  def __init__(self, path, experiment_name):\n",
    "    self.path = path\n",
    "    self.exp_name = experiment_name\n",
    "\n",
    "  def on_train_epoch_end(self, trainer, pl_module):\n",
    "    model_weights = pl_module.model.state_dict()\n",
    "    #self.path = self.path + self.exp_name +'.pt'\n",
    "    save_model({'model_state':model_weights}, self.path)\n",
    "\n",
    "class Get_Metrics(Callback):\n",
    "\n",
    "  def __init__(self):\n",
    "    r = 4\n",
    " \n",
    "  def on_train_epoch_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\"):\n",
    "\n",
    "    mean_train_loss = sum(pl_module.loss_train)/len(pl_module.loss_train)\n",
    "    \n",
    "    mean_test_loss = sum(pl_module.loss_test)/len(pl_module.loss_test)\n",
    "\n",
    "    pl_module.log(name = 'Loss on train', value = mean_train_loss)\n",
    "    pl_module.log(name = 'Loss on test', value = mean_test_loss)\n",
    "\n",
    "    R_prt = torch.corrcoef(pl_module.R_prt)[0,1].item()\n",
    "    R_elc = torch.corrcoef(pl_module.R_elc)[0,1].item()\n",
    "\n",
    "    pl_module.log(name = 'Electron Density correlation (R)', value = R_elc)\n",
    "    pl_module.log(name = 'Proton Density correlation (R)', value = R_prt)\n",
    "\n",
    "\n",
    "    pl_module.loss_train = []\n",
    "    pl_module.loss_test = []\n",
    "    pl_module.R_elc = torch.tensor([[]])  \n",
    "    pl_module.R_prt = torch.tensor([[]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, experiment_name):\n",
    "        super().__init__()\n",
    "        self.model = model #HeliosNet(n_channels, n_hidden_channels, kernel_size, batch_first, bias)\n",
    "        self.MSE = nn.MSELoss(reduction = 'mean')\n",
    "        self.training_hp = training_hp\n",
    "        self.loss_train = []\n",
    "        self.loss_test = []\n",
    "        self.R_elc = torch.tensor([[]])   #\n",
    "        self.R_prt = torch.tensor([[]])\n",
    "        \n",
    "        #self.save_hyperparameters()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        input = batch[0]     # Input of size (batch_size x timesteps_length x n_channels x height x width)\n",
    "        targets = batch[1]   # Output of size (batch_size x 2).\n",
    "\n",
    "        output = self.model(input)\n",
    "        \n",
    "        loss = self.MSE(output, targets)\n",
    "\n",
    "        self.loss_train.append(loss.item())\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        input = batch[0]     # Input of size (batch_size x timesteps_length x n_channels x height x width)\n",
    "        targets = batch[1]   # Output of size (batch_size x 2).\n",
    "\n",
    "        output = self.model(input)\n",
    "        \n",
    "        loss = self.MSE(output, targets)\n",
    "        self.loss_test.append(loss.item())\n",
    "\n",
    "        if self.R_prt.shape[1] != 0:\n",
    "            cat_prt = torch.cat((output[:,0].unsqueeze(0), targets[:, 0].unsqueeze(0)), dim = 0)\n",
    "            cat_elc = torch.cat((output[:,1].unsqueeze(0), targets[:, 1].unsqueeze(0)), dim = 0)\n",
    "\n",
    "            self.R_prt = torch.cat((self.R_prt, cat_prt), dim = 1)\n",
    "            self.R_elc = torch.cat((self.R_elc, cat_elc), dim = 1)\n",
    "        else:\n",
    "            self.R_prt = torch.cat((output[:,0].unsqueeze(0), targets[:, 0].unsqueeze(0)), dim = 0)\n",
    "            self.R_elc = torch.cat((output[:,1].unsqueeze(0), targets[:, 1].unsqueeze(0)), dim = 0)\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = self.training_hp['lr'], weight_decay = self.training_hp['wd'])\n",
    "\n",
    "        return self.optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'lr_e-5_wd_e-1_complex'\n",
    "load = False\n",
    "save = True\n",
    "\n",
    "path = './models/'+exp_name+'.pt'\n",
    "model = HeliosNet(n_channels, n_hidden_channels, kernel_size, batch_first, bias)\n",
    "if load:\n",
    "    \n",
    "    load_model(path, model, device)\n",
    "pl_training_MDL = TrainingModule(model, experiment_name = exp_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "num_gpu = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "\n",
    "if wb:\n",
    "    # initialise the wandb logger and name your wandb project\n",
    "    wandb_logger = WandbLogger(project=project_name, name = exp_name, config = training_hp, entity = 'small_sunbirds')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = training_hp['epochs'],  # maximum number of epochs.\n",
    "        gpus=num_gpu,  # the number of gpus we have at our disposal.\n",
    "        default_root_dir=\"\", logger = wandb_logger, callbacks = [Get_Metrics()]\n",
    "    )\n",
    "    if save:\n",
    "        trainer.callbacks.append(Save_Model_(path, exp_name))\n",
    "\n",
    "else:\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = training_hp['epochs'],  # maximum number of epochs.\n",
    "        gpus=num_gpu,  # the number of gpus we have at our disposal.\n",
    "        default_root_dir=\"\", callbacks = [Get_Metrics()] \n",
    "    )\n",
    "    if save:\n",
    "        trainer.callbacks.append(Save_Model_(path, exp_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | HeliosNet | 75.6 M\n",
      "1 | MSE   | MSELoss   | 0     \n",
      "------------------------------------\n",
      "75.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.6 M    Total params\n",
      "302.524   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 104/104 [01:45<00:00,  1.01s/it, loss=16.4]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/massimo/Documents/GitHub/Solar_wind_density_forecasting/wandb/run-20230108_014543-19bwq6t4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/small_sunbirds/A%20CNN-LSTM%20framework%20for%20the%20solar%20wind%20density%20forecasting/runs/19bwq6t4\" target=\"_blank\">lr_e-5_wd_e-1_complex</a></strong> to <a href=\"https://wandb.ai/small_sunbirds/A%20CNN-LSTM%20framework%20for%20the%20solar%20wind%20density%20forecasting\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  11%|█         | 11/104 [00:16<02:18,  1.49s/it, loss=19.9, v_num=q6t4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/massimo/anaconda3/envs/my_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  11%|█         | 11/104 [00:25<03:38,  2.35s/it, loss=19.9, v_num=q6t4]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model = pl_training_MDL, datamodule = SettingData)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty1 = torch.tensor([])\n",
    "\n",
    "\n",
    "train = torch.randn((16, 2))\n",
    "target = torch.randn((16, 2))\n",
    "\n",
    "cat = torch.cat((train[:,0].unsqueeze(0), target[:, 0].unsqueeze(0)), dim = 0)\n",
    "\n",
    "empty1 = torch.cat((empty1, cat), dim = 1)\n",
    "empty1.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[]]).shape[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb5a675a6478541207fdb7e1ef2fc54cbdc8ccd750b3ebebb7128ccf3ecf3278"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
