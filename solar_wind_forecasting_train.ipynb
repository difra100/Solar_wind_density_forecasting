{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A CNN-LSTM framework for the solar wind density forecasting\n",
    "## ConvLSTM training\n",
    "In this notebook we train a ConvLSTM network to predict solar wind densities (electrons + protons)\n",
    "\n",
    "\n",
    "#### Notebook Contributors\n",
    "* Andrea Giuseppe Di Francesco -- email: difrancesco.1836928@studenti.uniroma1.it\n",
    "* Massimo Coppotelli -- email: coppotelli.1705325@studenti.uniroma1.it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install matplotlib\n",
    "# !pip install torchvision\n",
    "# !pip install wandb\n",
    "# !pip3 install pytorch-lightning==1.5.10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "# Personal files\n",
    "from convlstm import *\n",
    "from cnn_lstm import *\n",
    "\n",
    "from utils import *\n",
    "from init import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdifra00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "Global seed set to 312023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "312023"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if wb:\n",
    "    wandb.login()\n",
    "\n",
    "SEED = 312023\n",
    "\n",
    "pl.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dataset = pd.read_csv('./datasets/wind_dataset_0.5d_res.csv', index_col = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch lightning code \n",
    "- Need of a collate function to preprocess data: sun_images are expressed as lists in a json files, thus we need a preprocessing before feed them into the ConvLSTM.\n",
    "- Then we define a Lightning DataModule, and finally the Lightining Module for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pl_Dataset_(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self,  dataset, bs):\n",
    "      \n",
    "\n",
    "      self.train_set = dataset.loc[0:round(len(dataset)*train_split)]\n",
    "      self.val_set = dataset.loc[round(len(dataset)*train_split)+1: round(len(dataset)*train_split) + round(len(dataset)*val_split)]\n",
    "\n",
    "      self.bs = bs\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        if stage == 'fit':\n",
    "            self.train_dataset = DataSet(self.train_set)\n",
    "        elif stage == 'test':\n",
    "            self.val_dataset = DataSet(self.val_set)\n",
    "            \n",
    "\n",
    "    def train_dataloader(self, *args, **kwargs):\n",
    "        return DataLoader(self.train_dataset, batch_size = self.bs, shuffle = False, collate_fn = collate) #, transform = transform)  Transformation was already made during the processing\n",
    "\n",
    "    def val_dataloader(self, *args, **kwargs):\n",
    "        return DataLoader(self.val_dataset, batch_size = self.bs, shuffle = False, collate_fn = collate) #, transform = transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SettingData = pl_Dataset_(wind_dataset, batch_size)\n",
    "\n",
    "SettingData.setup('fit')\n",
    "SettingData.setup('test')\n",
    "\n",
    "if mod == 'conv':\n",
    "    hyperparameters = training_hp\n",
    "elif mod == 'cnnlstm':\n",
    "    hyperparameters = training_hp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Save_Model_(Callback):\n",
    "\n",
    "  ''' This Callback is fundamental to save the model, and also its performances over time. It considers also if we want to save the model, given a path, or if we do not want to do so. '''\n",
    "  def __init__(self, path, experiment_name):\n",
    "    self.path = path\n",
    "    self.exp_name = experiment_name\n",
    "\n",
    "  def on_train_epoch_end(self, trainer, pl_module):\n",
    "    model_weights = pl_module.model.state_dict()\n",
    "    #self.path = self.path + self.exp_name +'.pt'\n",
    "    save_model({'model_state':model_weights}, self.path)\n",
    "\n",
    "class Get_Metrics(Callback):\n",
    "\n",
    "  def __init__(self):\n",
    "    r = 4\n",
    " \n",
    "  def on_train_epoch_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\"):\n",
    "\n",
    "    mean_train_loss = sum(pl_module.loss_train)/len(pl_module.loss_train)\n",
    "    \n",
    "    mean_test_loss = sum(pl_module.loss_test)/len(pl_module.loss_test)\n",
    "\n",
    "    pl_module.log(name = 'Loss on train', value = mean_train_loss)\n",
    "    pl_module.log(name = 'Loss on test', value = mean_test_loss)\n",
    "    R_prt = torch.corrcoef(pl_module.R_prt)[0,1].item()\n",
    "    R_elc = torch.corrcoef(pl_module.R_elc)[0,1].item()\n",
    "    pl_module.log(name = 'Electron Density correlation (R)', value = R_elc)\n",
    "    pl_module.log(name = 'Proton Density correlation (R)', value = R_prt)\n",
    "\n",
    "\n",
    "    pl_module.loss_train = []\n",
    "    pl_module.loss_test = []\n",
    "    pl_module.R_elc = torch.tensor([[]])  \n",
    "    pl_module.R_prt = torch.tensor([[]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, experiment_name):\n",
    "        super().__init__()\n",
    "        self.model = model #HeliosNet(n_channels, n_hidden_channels, kernel_size, batch_first, bias)\n",
    "        self.MSE = nn.MSELoss(reduction = 'mean')\n",
    "        self.training_hp = hyperparameters\n",
    "        self.loss_train = []\n",
    "        self.loss_test = []\n",
    "        self.R_elc = torch.tensor([[]])   #\n",
    "        self.R_prt = torch.tensor([[]])\n",
    "        \n",
    "        #self.save_hyperparameters()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        input = batch[0]     # Input of size (batch_size x timesteps_length x n_channels x height x width)\n",
    "        targets = batch[1]   # Output of size (batch_size x 2).\n",
    "\n",
    "        output = self.model(input)\n",
    "        \n",
    "        output = output[0:targets.shape[0],:]\n",
    "\n",
    "        loss = self.MSE(output, targets)\n",
    "\n",
    "        self.loss_train.append(loss.item())\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        input = batch[0]     # Input of size (batch_size x timesteps_length x n_channels x height x width)\n",
    "        targets = batch[1]   # Output of size (batch_size x 2).\n",
    "\n",
    "        output = self.model(input)\n",
    "        output = output[0:targets.shape[0],:]\n",
    "        loss = self.MSE(output, targets)\n",
    "        self.loss_test.append(loss.item())\n",
    "\n",
    "        if self.R_prt.shape[1] != 0:\n",
    "            cat_prt = torch.cat((output[:,0].unsqueeze(0), targets[:, 0].unsqueeze(0)), dim = 0)\n",
    "            cat_elc = torch.cat((output[:,1].unsqueeze(0), targets[:, 1].unsqueeze(0)), dim = 0)\n",
    "\n",
    "            self.R_prt = torch.cat((self.R_prt, cat_prt), dim = 1)\n",
    "            self.R_elc = torch.cat((self.R_elc, cat_elc), dim = 1)\n",
    "        else:\n",
    "            self.R_prt = torch.cat((output[:,0].unsqueeze(0), targets[:, 0].unsqueeze(0)), dim = 0)\n",
    "            self.R_elc = torch.cat((output[:,1].unsqueeze(0), targets[:, 1].unsqueeze(0)), dim = 0)\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = self.training_hp['lr'], weight_decay = self.training_hp['wd'])\n",
    "\n",
    "        return self.optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = CNN_LSTMmodule()\n",
    "# t = torch.randn((12,4,1,224,224))\n",
    "# out = s(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in SettingData.val_dataloader():\n",
    "    \n",
    "    out = s(i[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 1, 224, 224])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49msum(out[\u001b[39m1\u001b[39;49m][\u001b[39m0\u001b[39;49m], dim \u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "torch.sum(out[1][0], dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "exp_name = '0.5_CNNLSTM_lr_e-5_wd_e-1'\n",
    "load = False\n",
    "save = False\n",
    "\n",
    "path = './models/'+exp_name+'.pt'\n",
    "\n",
    "\n",
    "if mod == 'conv':\n",
    "    model = HeliosNet(n_channels, n_hidden_channels, kernel_size, n_layers, batch_first, bias, p_drop = training_hp['ConvLSTM_drop'])\n",
    "\n",
    "elif mod == 'cnnlstm':\n",
    "    model = CNN_LSTMmodule()\n",
    "\n",
    "if load:\n",
    "    \n",
    "    load_model(path, model, device)\n",
    "pl_training_MDL = TrainingModule(model, experiment_name = exp_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "num_gpu = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "\n",
    "if wb:\n",
    "    # initialise the wandb logger and name your wandb project\n",
    "    wandb_logger = WandbLogger(project=project_name, name = exp_name, config = hyperparameters, entity = 'small_sunbirds')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = hyperparameters['epochs'],  # maximum number of epochs.\n",
    "        gpus=num_gpu,  # the number of gpus we have at our disposal.\n",
    "        default_root_dir=\"\", logger = wandb_logger, callbacks = [Get_Metrics()]\n",
    "    )\n",
    "    if save:\n",
    "        trainer.callbacks.append(Save_Model_(path, exp_name))\n",
    "\n",
    "else:\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = hyperparameters['epochs'],  # maximum number of epochs.\n",
    "        gpus=num_gpu,  # the number of gpus we have at our disposal.\n",
    "        default_root_dir=\"\", callbacks = [Get_Metrics()] \n",
    "    )\n",
    "    if save:\n",
    "        trainer.callbacks.append(Save_Model_(path, exp_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type           | Params\n",
      "-----------------------------------------\n",
      "0 | model | CNN_LSTMmodule | 7.9 M \n",
      "1 | MSE   | MSELoss        | 0     \n",
      "-----------------------------------------\n",
      "7.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 M     Total params\n",
      "31.513    Total estimated model params size (MB)\n",
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/peppe/Desktop/Università/Projects/Solar_wind_density_forecasting/0.5_CNNLSTM_lr_e-5_wd_e-1/version_None/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a36adb93f8449ca99933f3bfd8d626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 312023\n",
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c01731395714d369259befbe00bb4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf040d415b245bc9c222be0dde3045e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdifra00\u001b[0m (\u001b[33msmall_sunbirds\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/peppe/Desktop/Università/Projects/Solar_wind_density_forecasting/wandb/run-20230110_194254-2yy189p2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/small_sunbirds/A%20CNN-LSTM%20framework%20for%20the%20solar%20wind%20density%20forecasting/runs/2yy189p2\" target=\"_blank\">0.5_CNNLSTM_lr_e-5_wd_e-1</a></strong> to <a href=\"https://wandb.ai/small_sunbirds/A%20CNN-LSTM%20framework%20for%20the%20solar%20wind%20density%20forecasting\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0542256e5342af909df6b284584c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affc5e09a4d44b0083389b7acbabffef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b28e3c7bd25499689ebb30dc728b98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3da0710481844fcbc26c727341444ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec7d745a5af42a98ab4711298b57cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4cf97ed4a44c9886293f4811e88482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9223e9e1d941d1a6874453b7a24f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1a05b2d9b048fb913b5d829ada415d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d5561db0354457b08de41b85bea0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58e8ce34d684fad9ad1819829e3b45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9a0cc4334147f2acf9daa5a7431c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7b978459604c69b7223b0117c0b251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce254c83b2e42cfac560792c21e032a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263476e8f2764db596fd9e1b61a9b00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3209855e24c54ff9985839e056b37d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f648577f6472479f82ebee4243f268be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209c661dfe9c47b48800e6a422b460b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb668ac0cbf455db6607879a3f44b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9ecc3b94564662b4cc609445ec8d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a43c757c424a15b06cc54ab55c5532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2294332132fc498b968378b5daa639d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eaa08cb0935451c929b8999cacfd25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf198bb9bfa4835aa20f73cde921ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4666bd26c0f148468738ad2da30dd996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392f38fceac4440abfaf80d777dba8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e381a1e001194563a543b71352b284b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa964a3b7c74a8085dca2e508424d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed07c7dab5b468a91062506842139a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d169216e50c44a10b1f8fb0f36f669f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Electron Density correlation (R)</td><td>█▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss on test</td><td>█▆▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂</td></tr><tr><td>Loss on train</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Proton Density correlation (R)</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Electron Density correlation (R)</td><td>0.01507</td></tr><tr><td>Loss on test</td><td>17.09977</td></tr><tr><td>Loss on train</td><td>12.85415</td></tr><tr><td>Proton Density correlation (R)</td><td>-0.02316</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>trainer/global_step</td><td>2249</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0.5_CNNLSTM_lr_e-5_wd_e-1</strong>: <a href=\"https://wandb.ai/small_sunbirds/A%20CNN-LSTM%20framework%20for%20the%20solar%20wind%20density%20forecasting/runs/2yy189p2\" target=\"_blank\">https://wandb.ai/small_sunbirds/A%20CNN-LSTM%20framework%20for%20the%20solar%20wind%20density%20forecasting/runs/2yy189p2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230110_194254-2yy189p2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model = pl_training_MDL, datamodule = SettingData)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeliosNet(\n",
       "  (ConvLSTM): ConvLSTM(\n",
       "    (cell_list): ModuleList(\n",
       "      (0): ConvLSTMCell(\n",
       "        (conv): Conv2d(9, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (drop): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (1): ConvLSTMCell(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (drop): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (2): ConvLSTMCell(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (drop): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (3): ConvLSTMCell(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (drop): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (4): ConvLSTMCell(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (drop): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (DensityPredictor): PredictionModule(\n",
       "    (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (pool2d): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "    (drop): Dropout(p=0.5, inplace=False)\n",
       "    (flatten): Flatten()\n",
       "    (FC1): Linear(in_features=18432, out_features=1024, bias=True)\n",
       "    (FC2): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real: \n",
      " tensor([[0.7750, 0.9395],\n",
      "        [1.0350, 1.0774],\n",
      "        [1.6400, 1.6557],\n",
      "        [2.4500, 1.9147]])\n",
      "Predicted: \n",
      " tensor([[5.3729, 3.8337],\n",
      "        [5.3704, 3.8320],\n",
      "        [5.3736, 3.8343],\n",
      "        [5.3720, 3.8333]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[3.1450, 2.0417],\n",
      "        [5.4450, 5.7560],\n",
      "        [4.5400, 2.6724],\n",
      "        [3.1050, 1.3998]])\n",
      "Predicted: \n",
      " tensor([[5.3745, 3.8350],\n",
      "        [5.3773, 3.8373],\n",
      "        [5.3770, 3.8370],\n",
      "        [5.3821, 3.8403]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[ 8.2550,  6.7167],\n",
      "        [ 8.8500,  5.5202],\n",
      "        [19.9200, 14.8109],\n",
      "        [ 5.7800,  4.4608]])\n",
      "Predicted: \n",
      " tensor([[5.3808, 3.8399],\n",
      "        [5.3817, 3.8403],\n",
      "        [5.3736, 3.8346],\n",
      "        [5.3744, 3.8353]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[ 5.0400,  6.8342],\n",
      "        [ 7.2400,  3.6822],\n",
      "        [15.2550,  8.8776],\n",
      "        [ 1.1850,  0.8767]])\n",
      "Predicted: \n",
      " tensor([[5.3773, 3.8372],\n",
      "        [5.3767, 3.8368],\n",
      "        [5.3770, 3.8368],\n",
      "        [5.3783, 3.8378]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[6.5600, 4.4732],\n",
      "        [4.7600, 2.7959],\n",
      "        [4.8450, 3.0675],\n",
      "        [3.2750, 1.9267]])\n",
      "Predicted: \n",
      " tensor([[5.3590, 3.8244],\n",
      "        [5.3610, 3.8258],\n",
      "        [5.3581, 3.8236],\n",
      "        [5.3587, 3.8241]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[3.0200, 2.6593],\n",
      "        [5.0700, 3.3146],\n",
      "        [4.3750, 3.1516],\n",
      "        [5.1900, 4.5293]])\n",
      "Predicted: \n",
      " tensor([[5.3570, 3.8228],\n",
      "        [5.3563, 3.8223],\n",
      "        [5.3580, 3.8235],\n",
      "        [5.3581, 3.8237]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[ 5.0350,  3.3474],\n",
      "        [ 7.8500,  3.9534],\n",
      "        [ 4.8700,  3.5392],\n",
      "        [12.6400,  7.5368]])\n",
      "Predicted: \n",
      " tensor([[5.3590, 3.8243],\n",
      "        [5.3598, 3.8249],\n",
      "        [5.3659, 3.8293],\n",
      "        [5.3687, 3.8310]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[3.8000, 2.5892],\n",
      "        [1.4600, 1.6250],\n",
      "        [2.8850, 2.5619],\n",
      "        [3.1750, 2.5492]])\n",
      "Predicted: \n",
      " tensor([[5.3676, 3.8303],\n",
      "        [5.3678, 3.8305],\n",
      "        [5.3669, 3.8299],\n",
      "        [5.3710, 3.8328]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[1.7950, 1.6674],\n",
      "        [1.9550, 1.8770],\n",
      "        [2.2350, 2.1335],\n",
      "        [3.0100, 2.3129]])\n",
      "Predicted: \n",
      " tensor([[5.3685, 3.8313],\n",
      "        [5.3740, 3.8349],\n",
      "        [5.3739, 3.8346],\n",
      "        [5.3762, 3.8360]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[ 6.0950,  4.4736],\n",
      "        [ 4.8500,  3.7015],\n",
      "        [ 7.2850,  5.1396],\n",
      "        [11.0600,  8.9174]])\n",
      "Predicted: \n",
      " tensor([[5.3763, 3.8360],\n",
      "        [5.3790, 3.8379],\n",
      "        [5.3741, 3.8346],\n",
      "        [5.3746, 3.8351]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[ 4.5500,  3.8410],\n",
      "        [ 4.9750,  4.1224],\n",
      "        [17.1900, 17.1751],\n",
      "        [ 2.0600,  1.4823]])\n",
      "Predicted: \n",
      " tensor([[5.3749, 3.8355],\n",
      "        [5.3582, 3.8235],\n",
      "        [5.3577, 3.8236],\n",
      "        [5.3577, 3.8237]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[5.4550, 4.7673],\n",
      "        [5.5550, 5.0301],\n",
      "        [3.1200, 2.1395],\n",
      "        [2.2400, 1.1537]])\n",
      "Predicted: \n",
      " tensor([[5.3583, 3.8239],\n",
      "        [5.3548, 3.8216],\n",
      "        [5.3579, 3.8235],\n",
      "        [5.3523, 3.8196]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[3.0800, 2.4560],\n",
      "        [4.6450, 3.3573],\n",
      "        [6.1450, 2.9342],\n",
      "        [1.3150, 1.0577]])\n",
      "Predicted: \n",
      " tensor([[5.3601, 3.8253],\n",
      "        [5.3637, 3.8277],\n",
      "        [5.3615, 3.8260],\n",
      "        [5.3661, 3.8291]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[7.4600, 8.6968],\n",
      "        [3.1600, 2.7830],\n",
      "        [5.5550, 4.8831],\n",
      "        [2.9600, 2.4258]])\n",
      "Predicted: \n",
      " tensor([[5.3615, 3.8260],\n",
      "        [5.3646, 3.8282],\n",
      "        [5.3653, 3.8287],\n",
      "        [5.3722, 3.8335]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[3.8500, 1.9275],\n",
      "        [4.4500, 3.4892],\n",
      "        [7.4350, 4.7816],\n",
      "        [2.7300, 1.6336]])\n",
      "Predicted: \n",
      " tensor([[5.3729, 3.8339],\n",
      "        [5.3746, 3.8351],\n",
      "        [5.3779, 3.8375],\n",
      "        [5.3763, 3.8364]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[2.6850, 3.2507],\n",
      "        [2.4400, 2.7353],\n",
      "        [1.0350, 1.2703],\n",
      "        [0.8900, 1.2538]])\n",
      "Predicted: \n",
      " tensor([[5.3808, 3.8396],\n",
      "        [5.3802, 3.8391],\n",
      "        [5.3823, 3.8407],\n",
      "        [5.3835, 3.8412]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[0.9950, 1.3208],\n",
      "        [1.7100, 1.3757],\n",
      "        [2.7800, 1.8213],\n",
      "        [2.4600, 1.8287]])\n",
      "Predicted: \n",
      " tensor([[5.3815, 3.8398],\n",
      "        [5.3815, 3.8397],\n",
      "        [5.3806, 3.8392],\n",
      "        [5.3803, 3.8390]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[3.4550, 3.2345],\n",
      "        [3.0550, 2.7741],\n",
      "        [3.6150, 2.7806],\n",
      "        [7.4650, 6.4622]])\n",
      "Predicted: \n",
      " tensor([[5.3804, 3.8391],\n",
      "        [5.3819, 3.8399],\n",
      "        [5.3825, 3.8404],\n",
      "        [5.3803, 3.8394]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[5.8450, 3.3836],\n",
      "        [5.4000, 2.9743],\n",
      "        [3.6250, 2.6935],\n",
      "        [3.4650, 2.6984]])\n",
      "Predicted: \n",
      " tensor([[5.3786, 3.8381],\n",
      "        [5.3790, 3.8383],\n",
      "        [5.3794, 3.8387],\n",
      "        [5.3812, 3.8397]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[5.3250, 2.7905],\n",
      "        [4.9150, 3.3754],\n",
      "        [3.9900, 3.2790],\n",
      "        [3.9250, 2.5242]])\n",
      "Predicted: \n",
      " tensor([[5.3795, 3.8385],\n",
      "        [5.3735, 3.8343],\n",
      "        [5.3688, 3.8309],\n",
      "        [5.3682, 3.8305]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[3.7650, 3.4106],\n",
      "        [3.1050, 2.5353],\n",
      "        [3.1000, 2.7473],\n",
      "        [4.5700, 3.5554]])\n",
      "Predicted: \n",
      " tensor([[5.3672, 3.8300],\n",
      "        [5.3704, 3.8322],\n",
      "        [5.3669, 3.8298],\n",
      "        [5.3724, 3.8335]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[5.2150, 4.0700],\n",
      "        [8.5250, 6.3150],\n",
      "        [8.2750, 7.0142],\n",
      "        [9.1300, 6.5356]])\n",
      "Predicted: \n",
      " tensor([[5.3693, 3.8314],\n",
      "        [5.3647, 3.8281],\n",
      "        [5.3655, 3.8290],\n",
      "        [5.3631, 3.8271]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[18.0200,  3.0673],\n",
      "        [ 1.6600,  0.8728],\n",
      "        [ 5.7650,  0.1861],\n",
      "        [ 2.1650,  0.1756]])\n",
      "Predicted: \n",
      " tensor([[5.3600, 3.8250],\n",
      "        [5.3585, 3.8240],\n",
      "        [5.3607, 3.8256],\n",
      "        [5.3606, 3.8255]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[ 8.2150,  3.1510],\n",
      "        [10.1100,  7.1111],\n",
      "        [ 5.9650,  4.2557],\n",
      "        [ 5.5600,  3.8868]])\n",
      "Predicted: \n",
      " tensor([[5.3596, 3.8247],\n",
      "        [5.3591, 3.8245],\n",
      "        [5.3595, 3.8246],\n",
      "        [5.3608, 3.8255]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "real: \n",
      " tensor([[4.9150, 4.4484],\n",
      "        [6.5400, 5.0607],\n",
      "        [6.4050, 6.2817]])\n",
      "Predicted: \n",
      " tensor([[5.3561, 3.8222],\n",
      "        [5.3595, 3.8245],\n",
      "        [5.3633, 3.8273],\n",
      "        [0.0000, 0.0000]], device='cuda:0', grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "for i in SettingData.val_dataloader():\n",
    "    i[1].to(device)\n",
    "    i[0].to(device)\n",
    "\n",
    "    print('real: \\n',i[1])\n",
    "    out = model(i[0])\n",
    "    print('Predicted: \\n', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn((4, 5, 1, 224, 224))\n",
    "\n",
    "# output = model(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 224, 224])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d541b27ed3f6b3a2668175b94af942c53fef9dc2000d6033c45f742df07c856"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
