{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A CNN-LSTM framework for the solar wind density forecasting\n",
    "## ConvLSTM training\n",
    "In this notebook we train a ConvLSTM network to predict solar wind densities (electrons + protons)\n",
    "\n",
    "\n",
    "#### Notebook Contributors\n",
    "* Andrea Giuseppe Di Francesco -- email: difrancesco.1836928@studenti.uniroma1.it\n",
    "* Massimo Coppotelli -- email: coppotelli.1705325@studenti.uniroma1.it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install matplotlib\n",
    "# !pip install torchvision\n",
    "# !pip install wandb\n",
    "# !pip3 install pytorch-lightning==1.5.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peppe/miniconda3/envs/my_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "# Personal files\n",
    "from convlstm import *\n",
    "from utils import *\n",
    "from init import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdifra00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "if wb:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dataset = pd.read_csv('./datasets/wind_dataset_1d_res.csv', index_col = 0)\n",
    "sun_dataset = load_data('./datasets/ARI_image_dataset.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch lightning code \n",
    "- Need of a collate function to preprocess data: sun_images are expressed as lists in a json files, thus we need a preprocessing before feed them into the ConvLSTM.\n",
    "- Then we define a Lightning DataModule, and finally the Lightining Module for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pl_Dataset_(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self,  dataset, bs):\n",
    "      \n",
    "\n",
    "      self.train_set = dataset.loc[0:round(len(dataset)*train_split)]\n",
    "      self.val_set = dataset.loc[round(len(dataset)*train_split)+1: round(len(dataset)*train_split) + round(len(dataset)*val_split)]\n",
    "\n",
    "      self.bs = bs\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        if stage == 'fit':\n",
    "            self.train_dataset = DataSet(self.train_set)\n",
    "        elif stage == 'test':\n",
    "            self.val_dataset = DataSet(self.val_set)\n",
    "            \n",
    "\n",
    "    def train_dataloader(self, *args, **kwargs):\n",
    "        return DataLoader(self.train_dataset, batch_size = self.bs, shuffle = True, collate_fn = collate)\n",
    "\n",
    "    def val_dataloader(self, *args, **kwargs):\n",
    "        return DataLoader(self.val_dataset, batch_size = self.bs, shuffle = False, collate_fn = collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    ''' This is the collate_function for the DataLoader module of pytorch, indeed we just give the wind dataset, since it defines the dataset length, \n",
    "        and then we define the additional modules \n",
    "        INPUT: batch: batch_sizex(timestamp, proton_density, electron_density),\n",
    "        OUTPUT: tensor: batch_size x time_steps x image_channels x image_height x image_width,  batch_size x proton_density x electron_density\n",
    "    '''\n",
    "    tensor = torch.zeros((len(batch), H+1, 1, 224, 224))\n",
    "    density = torch.zeros((len(batch), 2)) # Proton and Electron Density tensor\n",
    "\n",
    "\n",
    "    for sample in batch:\n",
    "        d = 0\n",
    "\n",
    "        requested_images = get_history_images(sample[0], H, D, resolution) # sample[0] corrensponds to the date of the solar wind prediction date.\n",
    "\n",
    "        mid_tensor = torch.zeros((len(requested_images), 1, 224, 224))\n",
    "        density_pair = torch.tensor([sample[1], sample[2]])\n",
    "\n",
    "        for image_idx in range(len(requested_images)):\n",
    "\n",
    "            image_tensor = torch.tensor(sun_dataset[requested_images[image_idx]])\n",
    "\n",
    "            mid_tensor[image_idx] = image_tensor\n",
    "        \n",
    "        tensor[d] = mid_tensor\n",
    "        density[d] = density_pair\n",
    "\n",
    "        d += 1\n",
    "        \n",
    "    \n",
    "    return tensor, density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SettingData = pl_Dataset_(wind_dataset, batch_size)\n",
    "\n",
    "SettingData.setup('fit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for stronzo in SettingData.train_dataloader():\n",
    "    input = stronzo[0]\n",
    "    break\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeliosNet(n_channels, n_hidden_channels, kernel_size, batch_first, bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb5445bfbf8972ec5f7b2dac98ed41742e280e56e41d5d2d5df357ace3791bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
