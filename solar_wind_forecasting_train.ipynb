{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A CNN-LSTM framework for the solar wind density forecasting\n",
    "## ConvLSTM training\n",
    "In this notebook we train a ConvLSTM network to predict solar wind densities (electrons + protons)\n",
    "\n",
    "\n",
    "#### Notebook Contributors\n",
    "* Andrea Giuseppe Di Francesco -- email: difrancesco.1836928@studenti.uniroma1.it\n",
    "* Massimo Coppotelli -- email: coppotelli.1705325@studenti.uniroma1.it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install matplotlib\n",
    "# !pip install torchvision\n",
    "# !pip install wandb\n",
    "# !pip3 install pytorch-lightning==1.5.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "# Personal files\n",
    "from convlstm import *\n",
    "from utils import *\n",
    "from init import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdifra00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "if wb:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dataset = pd.read_csv('./datasets/wind_dataset_1d_res.csv', index_col = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch lightning code \n",
    "- Need of a collate function to preprocess data: sun_images are expressed as lists in a json files, thus we need a preprocessing before feed them into the ConvLSTM.\n",
    "- Then we define a Lightning DataModule, and finally the Lightining Module for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pl_Dataset_(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self,  dataset, bs):\n",
    "      \n",
    "\n",
    "      self.train_set = dataset.loc[0:round(len(dataset)*train_split)]\n",
    "      self.val_set = dataset.loc[round(len(dataset)*train_split)+1: round(len(dataset)*train_split) + round(len(dataset)*val_split)]\n",
    "\n",
    "      self.bs = bs\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        if stage == 'fit':\n",
    "            self.train_dataset = DataSet(self.train_set)\n",
    "        elif stage == 'test':\n",
    "            self.val_dataset = DataSet(self.val_set)\n",
    "            \n",
    "\n",
    "    def train_dataloader(self, *args, **kwargs):\n",
    "        return DataLoader(self.train_dataset, batch_size = self.bs, shuffle = True, collate_fn = collate) #, transform = transform)  Transformation was already made during the processing\n",
    "\n",
    "    def val_dataloader(self, *args, **kwargs):\n",
    "        return DataLoader(self.val_dataset, batch_size = self.bs, shuffle = False, collate_fn = collate) #, transform = transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SettingData = pl_Dataset_(wind_dataset, batch_size)\n",
    "\n",
    "SettingData.setup('fit')\n",
    "SettingData.setup('test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Save_Model_(Callback):\n",
    "\n",
    "  ''' This Callback is fundamental to save the model, and also its performances over time. It considers also if we want to save the model, given a path, or if we do not want to do so. '''\n",
    "  def __init__(self, path, experiment_name):\n",
    "    self.path = path\n",
    "    self.exp_name = experiment_name\n",
    "\n",
    "  def on_train_epoch_end(self, trainer, pl_module):\n",
    "    model_weights = pl_module.model.state_dict()\n",
    "    #self.path = self.path + self.exp_name +'.pt'\n",
    "    save_model({'model_state':model_weights}, self.path)\n",
    "\n",
    "class Get_Metrics(Callback):\n",
    "\n",
    "  def __init__(self):\n",
    "    r = 4\n",
    " \n",
    "  def on_train_epoch_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\"):\n",
    "\n",
    "    mean_train_loss = sum(pl_module.loss_train)/len(pl_module.loss_train)\n",
    "    \n",
    "    mean_test_loss = sum(pl_module.loss_test)/len(pl_module.loss_test)\n",
    "\n",
    "    pl_module.log(name = 'Loss on train', value = mean_train_loss)\n",
    "    pl_module.log(name = 'Loss on test', value = mean_test_loss)\n",
    "\n",
    "    R_prt = torch.corrcoef(pl_module.R_prt)[0,1].item()\n",
    "    R_elc = torch.corrcoef(pl_module.R_elc)[0,1].item()\n",
    "\n",
    "    pl_module.log(name = 'Electron Density correlation (R)', value = R_elc)\n",
    "    pl_module.log(name = 'Proton Density correlation (R)', value = R_prt)\n",
    "\n",
    "\n",
    "    pl_module.loss_train = []\n",
    "    pl_module.loss_test = []\n",
    "    pl_module.R_elc = torch.tensor([[]])  \n",
    "    pl_module.R_prt = torch.tensor([[]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, experiment_name):\n",
    "        super().__init__()\n",
    "        self.model = model #HeliosNet(n_channels, n_hidden_channels, kernel_size, batch_first, bias)\n",
    "        self.MSE = nn.MSELoss(reduction = 'mean')\n",
    "        self.training_hp = training_hp\n",
    "        self.loss_train = []\n",
    "        self.loss_test = []\n",
    "        self.R_elc = torch.tensor([[]])   #\n",
    "        self.R_prt = torch.tensor([[]])\n",
    "        \n",
    "        #self.save_hyperparameters()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        input = batch[0]     # Input of size (batch_size x timesteps_length x n_channels x height x width)\n",
    "        targets = batch[1]   # Output of size (batch_size x 2).\n",
    "\n",
    "        output = self.model(input)\n",
    "        \n",
    "        loss = self.MSE(output, targets)\n",
    "\n",
    "        self.loss_train.append(loss.item())\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        input = batch[0]     # Input of size (batch_size x timesteps_length x n_channels x height x width)\n",
    "        targets = batch[1]   # Output of size (batch_size x 2).\n",
    "\n",
    "        output = self.model(input)\n",
    "        \n",
    "        loss = self.MSE(output, targets)\n",
    "        self.loss_test.append(loss.item())\n",
    "\n",
    "        if self.R_prt.shape[1] != 0:\n",
    "            cat_prt = torch.cat((output[:,0].unsqueeze(0), targets[:, 0].unsqueeze(0)), dim = 0)\n",
    "            cat_elc = torch.cat((output[:,1].unsqueeze(0), targets[:, 1].unsqueeze(0)), dim = 0)\n",
    "\n",
    "            self.R_prt = torch.cat((self.R_prt, cat_prt), dim = 1)\n",
    "            self.R_elc = torch.cat((self.R_elc, cat_elc), dim = 1)\n",
    "        else:\n",
    "            self.R_prt = torch.cat((output[:,0].unsqueeze(0), targets[:, 0].unsqueeze(0)), dim = 0)\n",
    "            self.R_elc = torch.cat((output[:,1].unsqueeze(0), targets[:, 1].unsqueeze(0)), dim = 0)\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = self.training_hp['lr'], weight_decay = self.training_hp['wd'])\n",
    "\n",
    "        return self.optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'lr_e-5_wd_e-1_LONGERFCNET_2layers'\n",
    "load = False\n",
    "save = False\n",
    "\n",
    "path = './models/'+exp_name+'.pt'\n",
    "model = HeliosNet(n_channels, n_hidden_channels, kernel_size, n_layers, batch_first, bias, p_drop = training_hp['ConvLSTM_drop'])\n",
    "if load:\n",
    "    \n",
    "    load_model(path, model, device)\n",
    "pl_training_MDL = TrainingModule(model, experiment_name = exp_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "num_gpu = 1 if torch.cuda.is_available() else 0\n",
    "\n",
    "\n",
    "if wb:\n",
    "    # initialise the wandb logger and name your wandb project\n",
    "    wandb_logger = WandbLogger(project=project_name, name = exp_name, config = training_hp, entity = 'small_sunbirds')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = training_hp['epochs'],  # maximum number of epochs.\n",
    "        gpus=num_gpu,  # the number of gpus we have at our disposal.\n",
    "        default_root_dir=\"\", logger = wandb_logger, callbacks = [Get_Metrics()]\n",
    "    )\n",
    "    if save:\n",
    "        trainer.callbacks.append(Save_Model_(path, exp_name))\n",
    "\n",
    "else:\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = training_hp['epochs'],  # maximum number of epochs.\n",
    "        gpus=num_gpu,  # the number of gpus we have at our disposal.\n",
    "        default_root_dir=\"\", callbacks = [Get_Metrics()] \n",
    "    )\n",
    "    if save:\n",
    "        trainer.callbacks.append(Save_Model_(path, exp_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | HeliosNet | 18.9 M\n",
      "1 | MSE   | MSELoss   | 0     \n",
      "------------------------------------\n",
      "18.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 M    Total params\n",
      "75.543    Total estimated model params size (MB)\n",
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/peppe/Desktop/Università/Projects/Solar_wind_density_forecasting/lr_e-5_wd_e-1_LONGERFCNET_2layers/version_None/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84388665338a492c8af2aa5566ffc5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/pytorch_lightning/trainer/data_loading.py:432: UserWarning: The number of training samples (39) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ae57d318004225a0028028a87f336a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9671e3aea73943b18d94782a39d563a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdifra00\u001b[0m (\u001b[33msmall_sunbirds\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py 339 experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peppe/anaconda3/envs/my_env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model = pl_training_MDL, datamodule = SettingData)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [60, 30, 3, 3], expected input[4, 16, 224, 224] to have 30 channels, but got 16 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m ConvLSTM(n_channels, \u001b[39m2\u001b[39m\u001b[39m*\u001b[39mn_hidden_channels\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, kernel_size, n_layers, batch_first, bias, p_drop \u001b[39m=\u001b[39m training_hp[\u001b[39m'\u001b[39m\u001b[39mConvLSTM_drop\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m SettingData\u001b[39m.\u001b[39mval_dataloader():\n\u001b[0;32m----> 6\u001b[0m     output \u001b[39m=\u001b[39m model(i[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m      8\u001b[0m     \u001b[39m#print(output[0][0].shape, i[1])\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Università/Projects/Solar_wind_density_forecasting/convlstm.py:162\u001b[0m, in \u001b[0;36mConvLSTM.forward\u001b[0;34m(self, input_tensor, hidden_state)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39m#output_inner = []\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(seq_len):\n\u001b[0;32m--> 162\u001b[0m     h, c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcell_list[layer_idx](input_tensor\u001b[39m=\u001b[39;49mcur_layer_input[:, t, :, :, :],\n\u001b[1;32m    163\u001b[0m                                      cur_state\u001b[39m=\u001b[39;49m[h, c])\n\u001b[1;32m    164\u001b[0m     \u001b[39m#output_inner.append(h)\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[39m# layer_output = torch.stack(output_inner, dim=1)\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m# cur_layer_input = layer_output\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \n\u001b[1;32m    169\u001b[0m \u001b[39m#layer_output_list.append(layer_output)  # We should take the last element of this. \u001b[39;00m\n\u001b[1;32m    170\u001b[0m last_state_list\u001b[39m.\u001b[39mappend([h, c])          \u001b[39m# torch.equal(output[0][0][:,-1,:,:,:], output[1][0][0])\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Università/Projects/Solar_wind_density_forecasting/convlstm.py:50\u001b[0m, in \u001b[0;36mConvLSTMCell.forward\u001b[0;34m(self, input_tensor, cur_state)\u001b[0m\n\u001b[1;32m     46\u001b[0m h_cur, c_cur \u001b[39m=\u001b[39m cur_state\n\u001b[1;32m     48\u001b[0m combined \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([input_tensor, h_cur], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# concatenate along channel axis\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m combined_conv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(combined))\n\u001b[1;32m     51\u001b[0m cc_i, cc_f, cc_o, cc_g \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msplit(combined_conv, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_dim, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     52\u001b[0m i \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(cc_i)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [60, 30, 3, 3], expected input[4, 16, 224, 224] to have 30 channels, but got 16 channels instead"
     ]
    }
   ],
   "source": [
    "model = ConvLSTM(n_channels, 2*n_hidden_channels-1\n",
    ", kernel_size, n_layers, batch_first, bias, p_drop = training_hp['ConvLSTM_drop'])\n",
    "\n",
    "\n",
    "for i in SettingData.val_dataloader():\n",
    "\n",
    "    output = model(i[0])\n",
    "\n",
    "    #print(output[0][0].shape, i[1])\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d541b27ed3f6b3a2668175b94af942c53fef9dc2000d6033c45f742df07c856"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
